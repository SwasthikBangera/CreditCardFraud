# -*- coding: utf-8 -*-
"""CreditFraudDetection.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1sGxOS5AMzKlFU_VaiiFtgn05fC1fCgb9

Import dependencies
"""

import pandas as pd
import numpy as np
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score

"""Data Analysis"""

# Import the data
Credit_dataset = pd.read_csv('/content/creditcard.csv')

# First five rows of Dataset
Credit_dataset.head()

# Last five rows of Dataset
Credit_dataset.tail()

# No of rows/columns in dataset
Credit_dataset.shape

#Information of Dataset
Credit_dataset.info()

#Missing entries values in dataset
Credit_dataset.isnull().sum()

# Statistical information of dataset
Credit_dataset.describe()

# Type of the dataset
type(Credit_dataset)

#Remove rows with missing values
Credit_dataset = Credit_dataset.dropna()

# No of values in dataset
Credit_dataset.shape

#Distribution of transactions types
Credit_dataset['Class'].value_counts()

"""From above, label 0 is legit transaction while 1 is fradulent transaction. The dataset is clearly unbalanced"""

#Seperating data for analysis
legit = Credit_dataset[Credit_dataset.Class == 0]
fraud = Credit_dataset[Credit_dataset.Class == 1]

# No of values in new datasets 
legit.shape, fraud.shape

#Statistical Measures of new datasets
fraud.describe()

legit.describe()

# Compare values for both transactions
Credit_dataset.groupby('Class').mean()

"""Under Sampling - Build a sample dataset containing similar distribution of legit and fraud transactions since fraud transaction is only 492 in #"""

#Selecting 492 values of legit transactions
legit_sample = legit.sample(n=492)

# Concatenating two dataframes
New_Credit_Dataset = pd.concat((legit_sample, fraud), axis =0)

# First five row values of Concatenated dataset
New_Credit_Dataset.head()

# value counts of Concatenated dataset
New_Credit_Dataset.shape

# Comparing values
New_Credit_Dataset.groupby('Class').mean()

"""Splitting data into Features and Label"""

# Splitting features and label
X = New_Credit_Dataset.drop(columns='Class', axis=1)
Y = New_Credit_Dataset['Class']

print(X)
print(Y)

"""Splitting dataset into Train and test data"""

# Splitting into Train and test data
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, stratify=Y, random_state=2)

#Check the splitting
X.shape, X_train.shape, X_test.shape

"""Fitting the model"""

# Use Logistic Reg model
model = LogisticRegression()

# Training the data
Training_data = model.fit(X_train, Y_train)

"""Model Evaluation"""

# Accuracy score of training data
X_train_prediction = model.predict(X_train)
Train_data_accuracy = accuracy_score(X_train_prediction, Y_train)
print('The accuracy on training data : ', Train_data_accuracy)

# Accuracy score of test data
X_test_prediction = model.predict(X_test)
Test_data_accuracy = accuracy_score(X_test_prediction, Y_test)
print('The accuracy on test data : ', Test_data_accuracy)

